<H2> What is this? </H2>

<P> 
The entire history of game outcomes implies an expected score between
any two opponents.  We can do this even for two people who have never
played each other; it's enough that there's some third player they
have both played against, even if "indirectly" in the sense that if A
played B played C played D, then A has played D indirectly.
</P>

<P>
These expected point spreads are presented here in several different
ways.  
The bar graph shows expected outcomes against the currently
best player.
</P>

<P>
Next come two line graphs: these show the expected point
spreads historically, game by game.  The benchmark player here is not
the best player but rather someone closer to the average; this
separates the lines out a bit (where, rating everyone against the best
player, the weakest players' lines would all lie almost on top of one
another).  Small circles indicate who played (you should see exactly
two small circles vertically, in every case).  A thin (and somewhat
dim) vertical line shows the difference between the actual point
spread in that game (seen from the higher-rated player's point of
view), versus the expected point spread.  So if that vertical line points
up/down, the "favorite" did better/worse than expected.

Oh yeah, there are two of these line graphs.  The second is based on a
weighting scheme that assigns more weight to recent games.
</P>

<P>
At the bottom of the page we have a graph showing all the games.
Between every pair of nodes (corresponding to two players) there is
one directed edge for every game those two players have played.  Edges
point to the game loser, while the edge colors indicate the point
spread -- from dark blue for blowouts to dark red for very close games
(it's the spread mapped to the hue in HSV space, restricted to
[0,0.67]).  Players' vertical positions on the graph are in order of
their ratings, from top to bottom.  Thanks, graphviz!
</P>

<P>
The coin of this realm is, obviously, the expected point spread (EPS),
so just a few more informal words about that.  As you'd expect, these
EPSs change after every game.  When two players meet, if the favorite
wins by more than the EPS, then the EPS increases.  Conversely, if
the favorite wins by less than the EPS (or loses), the EPS decreases.
It's not just the EPS between those two that changes, though; the EPSs
are all interdependent.  For example, suppose player J is rated higher than
K who is in turn rated higher than L.  If J and L meet and the outcome
is not as good (for J) as expected, then not only does the
EPS between J and L narrow, but the EPS between K and L narrows and so
does the EPS between J and K, as the model reassesses all relative playing
strengths.
</P>

<H2> Technical Details </H2>
<P>
Those EPSs are not the lowest-level ingredient in the model.  At the
lowest level, we have a system of player ratings.  These ratings are
the parameters of a probabilistic model of game outcomes, estimated by
the method of <a
href="http://en.wikipedia.org/wiki/Maximum_likelihood">maximum
likelihood.</a> The model amounts to a function that gives a
probability for the entire set of game outcomes.  This function has
two sets of arguments -- the game results, and a set of parameters.
The player ratings are the parameter values that maximize the
probability; informally, these are the parameter values that make the
observed game outcomes as likely as possible under the model chosen.
</P>

<P> Suppose players rated <EM>a</EM> and <EM>b,</EM> respectively,
play a game.  I'm modeling the probability that <EM>a</EM> wins a
point off <EM>b</EM> as a function

<PRE>
      <EM>p(a,b) = exp(a-b)/( 1 + exp(a-b) ).</EM>
</PRE>

Notice <EM>p</EM> is monotonically increasing in <EM>a-b</EM>, and
ranges from 0 to 1.

<P>
The nature of both foosball and pingpong is that the game ends when one
player reaches 5 or 21 (yes, the win-by-2 rule in pingpong gums things up
a bit).  The losing score m therefore follows the <a href="http://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial distribution</a>; for <EM>w</EM> the winning score (5 in foosball,
21 or whatever in pingpong),
the probability of that w-to-m score is a function

<PRE>
     <EM>L(w,m,p(a,b)) = ([w-1+m]!/[m!(w-1)!]) p(a,b)^w (1-p(a,b))^m</EM>
</PRE>

<P> 
The likelihood of the entire data set (all our games) is the product
(I'm assuming successive games, as well as successive points, are
independent events) of the L functions of all the games, with w and m
set in each game to the winning and losing scores, and <EM>a,b</EM>
set to the relevant players' parameters.
<P>

<P>
The expected spread follows straightforwardly from the estimated
probabilities.  Viewing w (the winning score) as fixed (it actually
isn't because of the win-by-two rule but close enough), and m
(the losing score) as the only random variable, it should be plausible
enough that (asymptotically)

<PRE>
    <EM> w/(w+E(m)) = p </EM>
</PRE>

From here, straightforward algebraic manipulation yields

<PRE>
    <EM> w - E(m) = w - w((1-p)/p) </EM>
</PRE>

that <EM>w -E(m)</EM> being of course the expected point spread.
